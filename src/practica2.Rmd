---
title: "Práctica 2: limpieza, análisis y representación de los datos"
author: "Cristina Liánez López y Manuel Padrón Martínez"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r load_libraries, include=FALSE}
library(stringr)
library(VIM)


```

# 1. Detalles de la actividad

En esta actividad se elabora un caso práctico, consistente en el tratamiento de un conjunto de datos (en inglés, dataset), orientado a aprender a identificar los datos relevantes para un proyecto analítico y usar las herramientas de integración, limpieza, validación y análisis de las mismas.

# 2. Resolución 

### 2.1. Descripción del dataset 

El conjunto de datos objeto de análisis se ha obtenido a partir de un dataset libre disponible en Kaggle. 
Este conjunto de datos incluye información sobre diferentes marcas de vehículos nuevos y usados a la venta en los EE.UU. Los datos se obtuvieron haciendo uso de la técnica de _Web Scraping._ Está constituido por 2499 vehículos (filas o registros), de los que se han analizado 13 características (columnas) de cada uno.

Las características analizadas en este dataset son:

* **x**: valor para identificar las filas. Comienza en 0.

* **price**:	precio de venta del vehículo en $.

* **brand**:	marca del vehículo.

* **model**:  modelo del vehículo.

* **year**:	año de la primera matriculación del vehículo.

* **Title_Status**:	Esta característica incluye dos posibles valores: _clean title_ que significa que el vehículo es apto para circular; o _salvage insurance_ en caso de que no sea apto para circular debido a que está dañado por un accidente, inundación, incendio, o cualquier otra circunstancia.

* **Mileage**: kilometraje del vehículo, expresado en millas.

* **Color**:	Color del vehículo.

* **Vin**:  Número de bastidor. Compuesto por 17 carácteres (números y letras)

* **Lot**:	es un número de identificación asignado a una cantidad determinada o un lote de coches de un solo fabricante. En este caso, se combina un número de lote con un número de serie para formar el número de identificación del vehículo.

* **State**:	estado o ciudad donde se encuentra el vehículo.

* **Country**: país donde se encuentra el vehículo.

* **Condition**:	tiempo que hace que se publicó el anuncio de venta del vehículo en la página web.

### 2.2. Integración y selección de los datos de interés a analizar.








### 2.3. Limpieza de los datos 

En primer lugar, procedemos a realizar la lectura del fichero en formato CSV en el que se encuentran los datos. A continuación, examinaremos el tipo de datos con los que R ha interpretado cada variable.

```{r chunck1}
# Carga del archivo
setwd("C:/Users/clian/Desktop/Data Science/Tipologia y ciclo de vida datos/Pract2/Lianez_Padron")
cars <-read.csv("USA_cars_datasets.csv",header=TRUE)

#muestra las primeras filas del dataset
head(cars)

#Examino el tipo de datos de cada variable
str(cars)

```

Puede observarse que los tipos de datos asignados automáticamente por R a las variables se corresponden con el dominio de estas.

De las 13 características registradas de cada vehículo, se ha decido prescindir de **x**, **lot** y **condition**, ya que no son atributos propios de los vehículos, sino que hacen referencia a los anuncios en los que se publicitaban a los mismos.

```{r chunck2}
# Prescindimos de las variables X, lot y condition
cars <- cars[,-(1)]
cars <- cars[,-(9)]
cars <- cars[,-(11)]
str(cars)
head(cars)

```

#### 2.3.1. Normalización de variables

A continuación, mostraremos los valores de las variables cualitativas o categóricas mediante el uso de tablas de frecuencia. Ésto nos permitirá saber si hay valores fuera del rango o valores extraños en ellas. 

```{r chunck3}
#variables cualitativas
table(cars$brand)
table(cars$model)
table(cars$title_status)
table(cars$color)
table(cars$state)
table(cars$country)
```

Los colores se van a clasificar en los siguientes valores: _beige, black, blue, brown, orange, gold, red, silver, white, gray, green, purple, yellow, no-color_ 

```{r chunck4}
cars$color <- str_replace(cars$color, ".*beige.*", "beige")
cars$color <- str_replace(cars$color, ".*black.*", "black")
cars$color <- str_replace(cars$color, ".*blue.*", "blue")
cars$color <- str_replace(cars$color, ".*brown.*", "brown")
cars$color <- str_replace(cars$color, ".*orange.*", "orange")
cars$color <- str_replace(cars$color, ".*gold.*", "gold")
cars$color <- str_replace(cars$color, ".*red.*", "red")
cars$color <- str_replace(cars$color, ".*silver.*", "silver")
cars$color <- str_replace(cars$color, ".*white.*", "white")
cars$color <- str_replace(cars$color, ".*gray.*", "gray")
cars$color <- str_replace(cars$color, ".*green.*", "green")
cars$color <- str_replace(cars$color, ".*purple.*", "purple")
cars$color <- str_replace(cars$color, ".*yellow.*", "yellow")
cars$color <- str_replace(cars$color, "burgundy", "red")
cars$color <- str_replace(cars$color, "charcoal", "black")
cars$color <- str_replace(cars$color, "color:", "no_color")
cars$color <- str_replace(cars$color, "maroon", "brown")
cars$color <- str_replace(cars$color, "magnetic metallic", "black")
cars$color <- str_replace(cars$color, "royal crimson metallic tinted clearcoat", "purple")
cars$color <- str_replace(cars$color, "turquoise", "blue")
cars$color <- str_replace(cars$color, "tan", "beige")
cars$color <- str_replace(cars$color, "guard", "black")

table(cars$color)

```

#### 2.3.2. Valores perdidos 

¿Los datos contienen ceros o elementos vacíos? ¿Cómo gestionarías cada uno de estos casos?

```{r chunck5}
# valores perdidos(0 o vacíos)
#Con la siguiente instrucción vemos si hay registros que están incompletos
complete.cases(cars)

#Analizamos valores perdidos
sapply(cars, function(x) sum(is.na(x)))
sapply(cars, function(x) sum(x == 0))
```

En primer lugar, hemos comprobado si hay registros incompletos, es decir, en los que en alguno de sus atributos no se haya introducido valor. Con la instrucciones ejecutada, se comprueba que no hay ninguno, ya que no se ha obtenido ningún valor a **FALSE**.

En segundo lugar, se ha analizado en cada una de las variables cuantitativas si existen valores almacenados equivalentes a 0 o NA. En el caso del precio, se han detectado 43 registros cuyo precio es 0; y para el caso del kilometraje, se han encontrado 6 registros con este mismo valor.

En el caso de la variable _price_, son claramente valores perdidos ya que no tiene sentido que el precio de venta fijado sea de 0$ cuando la naturaleza de los anuncios es la venta de los vehículos. Será necesario imputar los valores de estas variables en estos registros.

En el caso de la variable _mileage_ cuyo valor es 0, se ha mirado el valor del atributo _year_, puesto que si éste valor se corresponde con coches del 2020, el valor registrado en el atributo _mileage_ puede ser correcto ya que se trataría de vehículos nuevos que no han recorrido ninguna milla aún. 


```{r chunck6}

years <- subset(cars$year, subset = cars$mileage == 0)
print(years)

```

Trás realizar la comprobación, vemos que no es así en ninguno de los casos, es decir, son vehículos con cierta antigüedad, por lo que el valor a 0 de _mileage_ se corresponde con un valor perdido, que deberíamos de imputar.

Para la imputación de los valores perdidos se empleará un método basado en la similitud o diferencia entre los registros: la imputación basada en k vecinos más próximos (en inglés, kNN-imputation). La elección de esta alternativa se realiza bajo la hipótesis de que nuestros registros guardan cierta relación. No obstante, es mejor trabajar con datos “aproximados” que con los propios elementos vacíos, ya que obtendremos análisis con menor margen de error.

```{r chunck7}
#primero hay que sustituir los valores 0 por NA 
cars$price <- ifelse(cars$price == 0, NA, cars$price)
cars$mileage <- ifelse(cars$mileage == 0, NA, cars$mileage)
sapply(cars, function(x) sum(is.na(x)))

#imputamos los valores NA usando el método kNN
cars$price <- kNN(cars)$price
cars$mileage <- kNN(cars)$mileage

#comprobamos 
sapply(cars, function(x) sum(is.na(x)))
sapply(cars, function(x) sum(x == 0))


```


#### 2.3.3. Valores extremos.

Los valores extremos o outliers son aquellos que parecen no ser congruentes si los comparamos con el resto de los datos. Para identificarlos, utilizaremos la representación mediante un diagrama de caja.

```{r chunck8}
boxplot(cars$price)

boxplot(cars$year)

boxplot(cars$mileage)

summary(cars$price)
summary(cars$year)
summary(cars$mileage)
```

En los tres diagramas anteriores se observan bastantes valores outliers. Ésto es debido a que el rango de valores de las tres variables es bastante amplio. Si revisamos los datos y los comparamos con los valores resumen de cada variable, llegamos a la conclusión de que son valores posibles. Por tanto, se mantendrán tal y como están recogidos.

### 2.4. Análisis de los datos 

#### 2.4.1. Selección de los grupos de datos que se quieren analizar/comparar (planificación de los análisis a aplicar).

#### 2.4.2. Comprobación de la normalidad y homogeneidad de la varianza.

#### 2.4.3. Aplicación de pruebas estadísticas para comparar los grupos de datos.

En función de los datos y el objetivo del estudio, aplicar pruebas de contraste de hipótesis, correlaciones, regresiones, etc. Aplicar al menos tres métodos de análisis diferentes.

### 2.5. Representación de los resultados a partir de tablas y gráficas.

### 2.6. Conclusiones

### 2.7. Crear el archivo procesado. 



# 3. Recursos

1. Calvo M., Subirats L., Pérez D. (2019). Introducción a la limpieza y análisis de los datos. Editorial UOC.

2. Dalgaard, P. (2008). Introductory statistics with R. Springer Science & Business Media.

3. Megan Squire (2015). Clean Data. Packt Publishing Ltd.

4. Jiawei Han, Micheine Kamber, Jian Pei (2012). Data mining: concepts and techniques. Morgan Kaufmann.

5. Jason W. Osborne (2010). Data Cleaning Basics: Best Practices in Dealing with Extreme Scores. Newborn and Infant Nursing Reviews; 10 (1): pp. 1527-3369.

6. Wes McKinney (2012). Python for Data Analysis. O’Reilley Media, Inc.




7. Vegas, E. (2017). Preprocesamiento de datos. Material UOC.

8. Gibergans, J. (2017). Regresión lineal múltiple. Material UOC.

9. Rovira, C. (2008). Contraste de hipótesis. Material UOC.

Test for homogeneity of variances - Lavene’s test and the Fligner Killeen test (2016)[en línea]. bioSt@TS. [Consulta: 26 de diciembre de 2017] https://biostats.w.uib.no/test-for-homogeneity-of-variances-levenes-test/


